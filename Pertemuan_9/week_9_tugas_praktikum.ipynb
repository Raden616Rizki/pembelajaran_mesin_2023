{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1><strong>Tugas</strong></h1>\n",
        "\n",
        "- Lakukan klasifikasi pada data MNIST dengan menggunakan model ANN\n",
        "- Anda diperbolehkan melakukan eksplorasi terhadap,\n",
        "  - Metode pra pengolahan\n",
        "  - Pemilihan fitur\n",
        "  - Arsitektur ANN\n",
        "  - Fungsi Aktiviasi\n",
        "- ANN diimplementasikan dengan menggunakan tensorflow.\n",
        "- **DIKERJAKAN SECARA BERKELOMPOK**\n",
        "- **JELASKAN HASIL YANG ANDA DAPATKAN,**\n",
        "  - AKURASI\n",
        "  - CONFUSION MATRIX\n",
        "  - KONFIGURASI MODEL --> MULAI DARI PRA PENGOLAHAN SAMPAI ARSITEKTUR ANN"
      ],
      "metadata": {
        "id": "HM1BLDq88mjq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pra Pengolahan Data**"
      ],
      "metadata": {
        "id": "N51cpVl1L4kw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Langkah 1 - Import Library**"
      ],
      "metadata": {
        "id": "E_DieG5tMCoR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "IG3DtI7G8f3_"
      },
      "outputs": [],
      "source": [
        "import numpy as np # menyediakan dukungan untuk array multidimensi dan berbagai fungsi matematika\n",
        "import pandas as pd # menyediakan struktur data dan fungsi operasi data\n",
        "import tensorflow as tf # merupakan salah satu pustaka yang sangat populer untuk deep learning dan machine learning"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Langkah 2 - Load Data**"
      ],
      "metadata": {
        "id": "y8Vza5USMKBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unduh Dataset MNIST\n",
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "mnist = fetch_openml('mnist_784', parser='auto')\n",
        "\n",
        "# Ambil gambar pertama dan labelnya\n",
        "images, labels = mnist[\"data\"].to_numpy(), mnist[\"target\"].to_numpy()\n",
        "X = images.astype('float32')\n",
        "y = labels.astype('int')"
      ],
      "metadata": {
        "id": "wGFKyEiKKhM6"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Langkah 3 - Scaling Fitur**"
      ],
      "metadata": {
        "id": "IZ_S1LQwMRAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler # Membantu dalam standarisasi fitur\n",
        "\n",
        "sc = StandardScaler() # Membuat objek StandardScaler\n",
        "X = sc.fit_transform(X) # melakukan standarisasi pada data uji X"
      ],
      "metadata": {
        "id": "_1sitBGvMU8i"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Langkah 4 - Split Data**"
      ],
      "metadata": {
        "id": "UOg3AtLfN-TS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split # Digunakan untuk memisahkan data latih dan data uji\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0) # Melatih data train dan data test dengan rasio 80% da 20%\n",
        "\n",
        "# Fixing the dimensions of the train set\n",
        "X_train = X_train.astype('float32') / 255\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train , num_classes=10)\n",
        "\n",
        "# Fixing the dimensions of the test set\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "y_test = tf.keras.utils.to_categorical(y_test , num_classes=10)"
      ],
      "metadata": {
        "id": "uzfktDU9ODiq"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Membuat Model ANN**"
      ],
      "metadata": {
        "id": "fVq8TSsXOc53"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Langkah 1 - Inisiasi Model ANN**"
      ],
      "metadata": {
        "id": "gJNtRdKOOg_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ann = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "V_M5U2i-OmYp"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Langkah 2 - Membuat Input Layer dan Hidden Layer Pertama**"
      ],
      "metadata": {
        "id": "yQPBe5INOrk3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
      ],
      "metadata": {
        "id": "63zYkc6gOqHB"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Langkah 3 - Membuat Hidden Layer Kedua**"
      ],
      "metadata": {
        "id": "qMt4hyl1OzuD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
      ],
      "metadata": {
        "id": "jn1WApykO30X"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Langkah 4 - Membuat Output Layer**"
      ],
      "metadata": {
        "id": "2rApTiRCPAZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "WDfHZwniPDWO"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training Model**"
      ],
      "metadata": {
        "id": "BM5JfTyLPNcJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Langkah 1 - Compile Model (Menyatukan Arsitektur) ANN**"
      ],
      "metadata": {
        "id": "pSgxzl9vPPVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "LB3inl53PSFR"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Langkah 2 - Fitting Model**"
      ],
      "metadata": {
        "id": "2ZCWWmLUPVFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ann.fit(X_train, y_train, batch_size = 32, epochs = 100) # Melatih model ANN"
      ],
      "metadata": {
        "id": "eex0AS-pPYJ2",
        "outputId": "6f1b4a37-65ec-4c14-d768-6fb7579d35a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 738
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-5b0c7d958b7e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mann\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Melatih model ANN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1360, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1349, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1127, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1185, in compute_loss\n        return self.compiled_loss(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 2532, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5824, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((32, 1) vs (32, 10)).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Membuat Prediksi**"
      ],
      "metadata": {
        "id": "LJxsXwbWPdXL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prediksi Dengan Data Testing**"
      ],
      "metadata": {
        "id": "Y1b0C8IOSsK4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = ann.predict(X_test) # melakukan prediksi nilai berdasarkan X_test\n",
        "y_pred = (y_pred > 0.5)"
      ],
      "metadata": {
        "id": "1chNsekfSsj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cek Akurasi dan Confusion Matrix**"
      ],
      "metadata": {
        "id": "ZnUxdnyJPnvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score # Berguna dalam menghitung akurasi skor dan confusion matrix\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred) # menghitung confusion matrix berdasarkan hasil tes dan prediksi\n",
        "print(cm) # menampilkan hasil confusion matrix\n",
        "accuracy_score(y_test, y_pred) # menghitung dan menampilkan akurasi matrix berdasarkan hasil tes dan prediksi"
      ],
      "metadata": {
        "id": "sqvj8Xn9PxZ8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}